{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPE1GFU2YRT6e9cD2GYdr/c",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kevinkmcguigan/cloud2cloud/blob/main/cloud_cloud_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "c2c2 = big time WIP"
      ],
      "metadata": {
        "id": "KnivWqW6V7pl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "tVA-cwV_UYTE"
      },
      "outputs": [],
      "source": [
        "las_file_url = \"https://download-telecharger.services.geo.ca/pub/elevation/pointclouds_nuagespoints/NRCAN/St_Johns_2020_2/NL_StJohns_20210205_NAD83CSRS_UTMZ22_1km_E2690_N52270_CQL1_CLASS.copc.laz\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/potree/PotreeConverter.git"
      ],
      "metadata": {
        "id": "cUjU4QhWUo4A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/Kitware/CMake/releases/download/v3.16.0/cmake-3.16.0-Linux-x86_64.sh\n",
        "!chmod +x cmake-3.16.0-Linux-x86_64.sh\n",
        "!./cmake-3.16.0-Linux-x86_64.sh --skip-license --prefix=/usr/local"
      ],
      "metadata": {
        "id": "S7C0lI3mU1oe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd PotreeConverter\n",
        "!ls\n",
        "!mkdir build\n",
        "%cd build"
      ],
      "metadata": {
        "id": "DLGfSv8XVgxS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cmake ../"
      ],
      "metadata": {
        "id": "Qnslh3vqVh9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!make"
      ],
      "metadata": {
        "id": "XWADA2TBWEBz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import tempfile\n",
        "# Download the LAZ file to a temporary file\n",
        "with tempfile.NamedTemporaryFile(suffix=\".laz\", delete=False) as temp_laz_file:\n",
        "    response = requests.get(las_file_url)\n",
        "    temp_laz_file.write(response.content)\n",
        "    input_file = temp_laz_file.name\n"
      ],
      "metadata": {
        "id": "n4l7RWvNWEnx"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "def run_potree_converter(input_file, output_directory, additional_args=None):\n",
        "    # Define the path to the PotreeConverter executable\n",
        "    potree_converter_path = '/content/PotreeConverter/build/PotreeConverter'\n",
        "    \n",
        "    # Define the command arguments\n",
        "    args = [potree_converter_path, input_file, '-o', output_directory]\n",
        "    \n",
        "    # Add any additional arguments, if provided\n",
        "    if additional_args:\n",
        "        args.extend(additional_args)\n",
        "    \n",
        "    # Run the PotreeConverter command\n",
        "    result = subprocess.run(args, capture_output=True, text=True)\n",
        "    \n",
        "    # Print the output of the PotreeConverter command\n",
        "    print(result.stdout)\n",
        "    print(result.stderr)\n",
        "    \n",
        "    return result.returncode\n",
        "\n",
        "# Example usage\n",
        "# input_file = 'path/to/pointcloud.las'\n",
        "output_directory = '/content/potree_data'\n",
        "additional_args = ['-p', '5000']  # Optional additional arguments\n",
        "return_code = run_potree_converter(input_file, output_directory, additional_args)\n",
        "\n",
        "if return_code == 0:\n",
        "    print('PotreeConverter completed successfully.')\n",
        "else:\n",
        "    print('PotreeConverter encountered an error.')\n"
      ],
      "metadata": {
        "id": "i1nXVgFBXR0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#GPT4 attempt, with wrong metadata formatting\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import struct\n",
        "\n",
        "def read_hierarchy_bin(file_path, node_size):\n",
        "    with open(file_path, \"rb\") as f:\n",
        "        nodes = []\n",
        "        while True:\n",
        "            node_name_data = f.read(node_size)\n",
        "            if not node_name_data:\n",
        "                break\n",
        "            node_name = int.from_bytes(node_name_data, byteorder='little')\n",
        "            point_count = int.from_bytes(f.read(4), byteorder='little')\n",
        "            nodes.append((node_name, point_count))\n",
        "        return nodes\n",
        "\n",
        "def read_potree_bin(file_path, point_format, bbox_min, bbox_max):\n",
        "    point_data = []\n",
        "\n",
        "    def read_point(f):\n",
        "        point = {}\n",
        "        for attribute in point_format:\n",
        "            point_value = struct.unpack(attribute[\"type\"], f.read(attribute[\"size\"]))[0]\n",
        "            point[attribute[\"name\"]] = point_value\n",
        "        return point\n",
        "\n",
        "    with open(file_path, \"rb\") as f:\n",
        "        while True:\n",
        "            point = read_point(f)\n",
        "            coords = np.array([point[\"position\"][0], point[\"position\"][1], point[\"position\"][2]])\n",
        "            if np.all(bbox_min <= coords) and np.all(coords <= bbox_max):\n",
        "                point_data.append(coords)\n",
        "\n",
        "            if f.tell() == os.path.getsize(file_path):\n",
        "                break\n",
        "\n",
        "    return np.array(point_data)\n",
        "\n",
        "def load_points_from_hierarchy(metadata_file, hierarchy_file, data_folder, bbox_min, bbox_max):\n",
        "    with open(metadata_file, \"r\") as f:\n",
        "        metadata = json.load(f)\n",
        "\n",
        "    point_format = metadata[\"attributes\"]\n",
        "    node_size = len(metadata[\"stepSize\"].encode('utf-8'))\n",
        "    hierarchy_nodes = read_hierarchy_bin(hierarchy_file, node_size)\n",
        "    point_data = []\n",
        "\n",
        "    for node_name, point_count in hierarchy_nodes:\n",
        "        if point_count > 0:\n",
        "            file_path = os.path.join(data_folder, f\"{node_name}.bin\")\n",
        "            points_in_node = read_potree_bin(file_path, point_format, bbox_min, bbox_max)\n",
        "            if points_in_node.size > 0:\n",
        "                point_data.append(points_in_node)\n",
        "\n",
        "    return np.vstack(point_data) if point_data else np.array([])\n"
      ],
      "metadata": {
        "id": "h-X-4M0UYRAE"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = '/content/potree_data/pointclouds/5000/metadata.json'\n",
        "b = '/content/potree_data/pointclouds/5000/hierarchy.bin'\n",
        "c = '/content/potree_data/pointclouds/5000/octree.bin'\n",
        "d = 0\n",
        "e = 1000000000\n",
        "data = load_points_from_hierarchy()"
      ],
      "metadata": {
        "id": "OV23HXEMYVsF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#GPT3.5 attempt with metadata.json as prompt\n",
        "# never did get this to fully work to the point of producing a numpy array.\n",
        "# this may work for potreeconverter 1.7 files as it seems to traverse that file structure \n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import struct\n",
        "\n",
        "def read_potree_bin(file_path, point_format, bbox_min, bbox_max):\n",
        "    point_data = []\n",
        "    point_size = sum(attr[\"size\"] for attr in point_format)\n",
        "    \n",
        "    def read_point(f):\n",
        "        point = {}\n",
        "        for attribute in point_format:\n",
        "            point_value = struct.unpack(attribute[\"type\"], f.read(attribute[\"size\"]))[0]\n",
        "            point[attribute[\"name\"]] = point_value\n",
        "        return point\n",
        "\n",
        "    with open(file_path, \"rb\") as f:\n",
        "        while True:\n",
        "            point = read_point(f)\n",
        "            coords = np.array([point[\"position\"][0], point[\"position\"][1], point[\"position\"][2]])\n",
        "            if np.all(bbox_min <= coords) and np.all(coords <= bbox_max):\n",
        "                point_data.append(coords)\n",
        "\n",
        "            if f.tell() == os.path.getsize(file_path):\n",
        "                break\n",
        "\n",
        "    return np.array(point_data)\n",
        "\n",
        "def load_points_from_metadata(metadata_file, data_folder, bbox_min, bbox_max):\n",
        "    with open(metadata_file, \"r\") as f:\n",
        "        metadata = json.load(f)\n",
        "\n",
        "    point_format = [attr for attr in metadata[\"attributes\"] if attr[\"name\"] == \"position\"]\n",
        "    hierarchy = metadata[\"hierarchy\"]\n",
        "    first_chunk_size = hierarchy[\"firstChunkSize\"]\n",
        "    step_size = hierarchy[\"stepSize\"]\n",
        "    depth = hierarchy[\"depth\"]\n",
        "    point_data = []\n",
        "\n",
        "    def traverse_octree(node_name, current_depth):\n",
        "        if current_depth == depth:\n",
        "            file_path = os.path.join(data_folder, f\"{node_name}.bin\")\n",
        "            if os.path.exists(file_path):\n",
        "                points_in_node = read_potree_bin(file_path, point_format, bbox_min, bbox_max)\n",
        "                # print(points_in_node)\n",
        "                if points_in_node.size > 0:\n",
        "                    point_data.append(points_in_node)\n",
        "            return\n",
        "\n",
        "        for i in range(8):\n",
        "            child_node_name = f\"{node_name}{i}\"\n",
        "            # print(child_node_name)\n",
        "            traverse_octree(child_node_name, current_depth + 1)\n",
        "\n",
        "    traverse_octree(\"r\", 0)\n",
        "    return np.vstack(point_data) if point_data else np.array([])\n",
        "\n"
      ],
      "metadata": {
        "id": "bzlyr-g0apQ6"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "metadata_file = '/content/potree_data/pointclouds/5000/metadata.json'\n",
        "data_folder = '/content/potree_data/pointclouds/5000'\n",
        "bbox_min = np.array([269100, 5227100, 100])\n",
        "bbox_max = np.array([269200, 5227200, 200])\n",
        "points_in_bbox = load_points_from_metadata(metadata_file, data_folder, bbox_min, bbox_max)\n"
      ],
      "metadata": {
        "id": "g7t8LRDZa1n3"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "points_in_bbox"
      ],
      "metadata": {
        "id": "y3MWr9u4bnLm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import struct\n",
        "\n",
        "def read_hierarchy_bin(file_path, step_size):\n",
        "    with open(file_path, \"rb\") as f:\n",
        "        nodes = []\n",
        "        while True:\n",
        "            node_name_data = f.read(step_size)\n",
        "            if not node_name_data:\n",
        "                break\n",
        "            node_name = int.from_bytes(node_name_data, byteorder='little')\n",
        "            point_count = int.from_bytes(f.read(4), byteorder='little')\n",
        "            nodes.append((node_name, point_count))\n",
        "        return nodes\n",
        "\n",
        "\n",
        "def read_octree_bin(file_path, point_format, hierarchy, bbox_min, bbox_max):\n",
        "    point_data = []\n",
        "    point_size = sum(attr[\"size\"] for attr in point_format)\n",
        "    \n",
        "    def read_point(f):\n",
        "        point = {}\n",
        "        for attribute in point_format:\n",
        "            point_value = struct.unpack(attribute[\"type\"], f.read(attribute[\"size\"]))[0]\n",
        "            point[attribute[\"name\"]] = point_value\n",
        "        return point\n",
        "\n",
        "    with open(file_path, \"rb\") as f:\n",
        "        for node_name, point_count in hierarchy:\n",
        "            for _ in range(point_count):\n",
        "                point = read_point(f)\n",
        "                coords = np.array([point[\"position\"][0], point[\"position\"][1], point[\"position\"][2]])\n",
        "                if np.all(bbox_min <= coords) and np.all(coords <= bbox_max):\n",
        "                    point_data.append(coords)\n",
        "\n",
        "    return np.array(point_data)\n",
        "\n",
        "def load_points_from_hierarchy(metadata_file, hierarchy_file, octree_file, bbox_min, bbox_max):\n",
        "    with open(metadata_file, \"r\") as f:\n",
        "        metadata = json.load(f)\n",
        "\n",
        "    point_format = [attr for attr in metadata[\"attributes\"] if attr[\"name\"] == \"position\"]\n",
        "    hierarchy_step_size = metadata[\"hierarchy\"][\"stepSize\"]\n",
        "    hierarchy_nodes = read_hierarchy_bin(hierarchy_file, hierarchy_step_size)\n",
        "    print(hierarchy_nodes)\n",
        "    point_data = read_octree_bin(octree_file, point_format, hierarchy_nodes, bbox_min, bbox_max)\n",
        "\n",
        "    return point_data\n"
      ],
      "metadata": {
        "id": "4di_-H-zc58N"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metadata_file = '/content/potree_data/pointclouds/5000/metadata.json'\n",
        "hierarchy_file = '/content/potree_data/pointclouds/5000/hierarchy.bin'\n",
        "octree_file = '/content/potree_data/pointclouds/5000/octree.bin'\n",
        "bbox_min = np.array([269100, 5227100, 100])\n",
        "bbox_max = np.array([269200, 5227200, 200])\n",
        "points_in_bbox = load_points_from_hierarchy(metadata_file, hierarchy_file, octree_file, bbox_min, bbox_max)\n"
      ],
      "metadata": {
        "id": "OKDm2h-Sc_8_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ive ran out of gpt4 tokens and 3.5 is going off the rails. ill have to start again later i think it is getting close."
      ],
      "metadata": {
        "id": "hgBVGPxdgmWD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q pypotree --upgrade"
      ],
      "metadata": {
        "id": "KdQweEgegvVe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#modified from pypotree\n",
        "port = 0\n",
        "def display_cloud_colab(xyz, debug=False):\n",
        "\t\"\"\"\n",
        "\tDisplay a point cloud in the path generated by generate_cloud_for_display\n",
        "\tArguments:\n",
        "\t\txyz: a Nx3 matrix containing the 3D positions of N points\n",
        "\t\"\"\"\n",
        "\n",
        "\tglobal port\n",
        "\n",
        "\tif port == 0: \n",
        "\t\timport portpicker\n",
        "\t\timport threading\n",
        "\t\timport socket\n",
        "\t\timport IPython\n",
        "\n",
        "\t\tfrom six.moves import socketserver\n",
        "\t\tfrom six.moves import SimpleHTTPServer\n",
        "\n",
        "\t\timport time\n",
        "\n",
        "\t\tclass V6Server(socketserver.TCPServer):\n",
        "\t\t\taddress_family = socket.AF_INET6\n",
        "\n",
        "\t\tclass Handler(SimpleHTTPServer.SimpleHTTPRequestHandler):\n",
        "\t\t\tdef do_GET(self):\n",
        "\t\t\t\t#super().do_GET()\n",
        "\t\t\t\tself.send_response(200)\n",
        "\t\t\t\t# If the response should not be cached in the notebook for\n",
        "\t\t\t\t# offline access:\n",
        "\t\t\t\tself.send_header('x-colab-notebook-cache-control', 'no-cache')\n",
        "\t\t\t\tself.end_headers()\n",
        "\t\t\t\t\n",
        "\t\t\t\t#self.wfile.write(b'''hola!''')\n",
        "\t\t\t\tself.wfile.write(b'''\n",
        "\t\t\t\t    document.querySelector('#output-area').appendChild(document.createTextNode('Script result!'));\n",
        "                    ''')\n",
        "\t\t#global port\n",
        "\t\tport = portpicker.pick_unused_port()\n",
        "\n",
        "\t\t### SERVING ALL THE FILES\n",
        "\t\tHandler = SimpleHTTPServer.SimpleHTTPRequestHandler\n",
        "\n",
        "\t\tdef server_entry():\n",
        "\t\t\thttpd = V6Server(('::', port), Handler)\n",
        "\t\t\t# Handle a single request then exit the thread.\n",
        "\t\t\thttpd.serve_forever()\n",
        "\n",
        "\t\tthread = threading.Thread(target=server_entry)\n",
        "\t\tthread.start()\n",
        "  \n",
        "\t\tprint (\"server on port {}: thread {} \".format( port, thread ) )\n",
        "\n",
        "\n",
        "\t# text = open('point_clouds/{}.html'.format(xyz) ).read()\n",
        "\ttext = open(xyz).read()\n",
        "\n",
        "\t# pointcloudpath='https://localhost:{port}/point_clouds/pointclouds/{xyz}'.format(port=port, xyz=xyz)\n",
        "\tpointcloudpath='https://localhost:{port}/{xyz}'.format(port=port, xyz=xyz)\n",
        "\n",
        "\t# print(pointcloudpath)\n",
        "\tnewtext = text\n",
        "\t\n",
        "  \n",
        "\t# newtext = newtext.replace('\"./libs/potree/potree.js', '\"https://localhost:{port}/pypotree/src/potree.colab.js'.format(port=port) )\n",
        "  # newtext = newtext.replace('\"./libs/potree/potree.js', '\"https://raw.githubusercontent.com/centreborelli/pypotree/master/src/potree.colab.js' )\n",
        "\tnewtext = newtext.replace('\"./', '\"https://localhost:{port}/potree_data/'.format(port=port))\n",
        "\n",
        "\t# newtext = text.replace('src=\"', 'src=\"https://localhost:{port}/'.format(port=port))\n",
        "\t# newtext = newtext.replace('href=\"', 'href=\"https://localhost:{port}/'.format(port=port))\n",
        "\t#newtext = newtext.replace('\"pointclouds/', '\"https://localhost:{port}/pointclouds/'.format(port=port))\n",
        "\t# newtext = newtext.replace(xyz, pointcloudpath)\n",
        "\n",
        "\tnewtext = newtext.replace('width: 100%; height: 100%;', 'width: 100%; height: 500px;')\n",
        "\t# newtext = newtext.replace('libs/potree/potree.js', 'libs/potree/potree.colab.js' )\n",
        "\t\n",
        "\tif debug:\n",
        "\t\tprint(newtext)\n",
        "\n",
        "\t\n",
        "\telse:\n",
        "\t\timport IPython\n",
        "\t\treturn IPython.display.HTML(newtext)\n",
        " \n",
        "\n",
        " # soooo close to working....\n",
        " #something is wrong where the actual point cloud is not drawing. \n",
        " # perhaps the path is incorrect or the pypotree.colab.js is really needed..."
      ],
      "metadata": {
        "id": "SsnemZdnikEc"
      },
      "execution_count": 249,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/centreborelli/pypotree.git"
      ],
      "metadata": {
        "id": "YtK-PCDk0TmH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import pypotree\n",
        "# %cd /content/\n",
        "# !ls\n",
        "# pypotree.display_cloud_colab('/content/potree_data/5000.html')\n",
        "!ls\n",
        "display_cloud_colab('/content/potree_data/5000.html', debug=True) #turn off debug to show the html"
      ],
      "metadata": {
        "id": "_3OJ0OpQg9Es"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "open('/content/potree_data/5000.html').read()"
      ],
      "metadata": {
        "id": "Sa-GKedalouk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML\n",
        "\n",
        "# Define the path to the local HTML file\n",
        "html_file_path = '/content/potree_data/5000.html'\n",
        "\n",
        "# Read the contents of the HTML file\n",
        "with open(html_file_path, \"r\") as f:\n",
        "    html_content = f.read()\n",
        "\n",
        "# Display the HTML content\n",
        "HTML(html_content)"
      ],
      "metadata": {
        "id": "Ytf65MA1pL-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML\n",
        "\n",
        "# Define a simple HTML snippet\n",
        "html_content = \"<h1>Hello, World!</h1>\"\n",
        "\n",
        "# Display the HTML content\n",
        "HTML(html_content)"
      ],
      "metadata": {
        "id": "-Yh3kLJ7qljp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}